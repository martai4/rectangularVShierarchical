{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NORMALIZE CREATING NEW TABLE\n",
    "\n",
    "ta metoda polega na tworzeniu tabeli dla kaÅ¼dej listy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pyarrow as pa\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_test = [ '../data-test/airlines.json', \n",
    "            '../data-test/gists.json', \n",
    "            '../data-test/historical-events.json',#have to rename the same value in json (movie on  the same level)\n",
    "            '../data-test/movies.json',\n",
    "            '../data-test/reddit.json',#bad\n",
    "            '../data-test/nasa.json'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [ '../data/airlines.json', \n",
    "            '../data/gists.json', \n",
    "            '../data/historical-events.json',\n",
    "            '../data/movies.json',\n",
    "            '../data/reddit.json',\n",
    "            '../data/nasa.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_json(y):\n",
    "    out = {}\n",
    "\n",
    "    def flatten(x, name=''):\n",
    "        if type(x) is dict:\n",
    "            for a in x:\n",
    "                attribute_name= name + a +'.'\n",
    "                flatten(x[a], attribute_name)\n",
    "        elif type(x) is list:\n",
    "            i = 0\n",
    "            for a in x:\n",
    "                attribute_name=name.rstrip('.') + '[' + str(i) + '].'\n",
    "                flatten(a, attribute_name)\n",
    "                i += 1\n",
    "        else:\n",
    "            out[name.rstrip('.')] = x\n",
    "\n",
    "    flatten(y)\n",
    "    return out\n",
    "\n",
    "results = []\n",
    "\n",
    "for path in paths_test:\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        dt = json.load(f)\n",
    "        \n",
    "    if isinstance(dt, list):\n",
    "        flattened_data = [flatten_json(item) for item in dt]\n",
    "    else:\n",
    "        flattened_data = [flatten_json(dt)]\n",
    "\n",
    "    df = pd.DataFrame(flattened_data)\n",
    "\n",
    "    table = pa.Table.from_pandas(df)\n",
    "    results.append(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################\n",
      "##########main##########\n",
      "########################\n",
      "pyarrow.Table\n",
      "name: string\n",
      "id: string\n",
      "nametype: string\n",
      "recclass: string\n",
      "mass: string\n",
      "fall: string\n",
      "year: string\n",
      "reclat: string\n",
      "reclong: string\n",
      "geolocation.type: string\n",
      "row_number: int64\n",
      "----\n",
      "name: [[\"Aachen\",\"Aarhus\",\"Abee\"]]\n",
      "id: [[\"1\",\"2\",\"6\"]]\n",
      "nametype: [[\"Valid\",\"Valid\",\"Valid\"]]\n",
      "recclass: [[\"L5\",\"H6\",\"EH4\"]]\n",
      "mass: [[\"21\",\"720\",\"107000\"]]\n",
      "fall: [[\"Fell\",\"Fell\",\"Fell\"]]\n",
      "year: [[\"1880-01-01T00:00:00.000\",\"1951-01-01T00:00:00.000\",\"1952-01-01T00:00:00.000\"]]\n",
      "reclat: [[\"50.775000\",\"56.183330\",\"54.216670\"]]\n",
      "reclong: [[\"6.083330\",\"10.233330\",\"-113.000000\"]]\n",
      "geolocation.type: [[\"Point\",\"Point\",\"Point\"]]\n",
      "...\n",
      "geolocation.coordinates\n",
      "########################\n",
      "geolocation.coordinates\n",
      "########################\n",
      "pyarrow.Table\n",
      "row_number: int64\n",
      "value: double\n",
      "----\n",
      "row_number: [[0,0,1,1,2,2]]\n",
      "value: [[6.08333,50.775,10.23333,56.18333,-113,54.21667]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import json\n",
    "\n",
    "def make_new_json(lists,table_name):\n",
    "    print(table_name)\n",
    "    data = []\n",
    "    for i in range(len(lists)):\n",
    "        for item in lists[i]:\n",
    "            item_data={\n",
    "                \"row_number\": i,\n",
    "                \"value\": item\n",
    "            }\n",
    "            data.append(item_data)\n",
    "    return data\n",
    "\n",
    "def delete_lists(df,name):\n",
    "    \n",
    "    print(\"#\"*24)\n",
    "    print(\"#\"*((24-len(name))//2)+name+\"#\"*((24-len(name))//2))\n",
    "    print(\"#\"*24)\n",
    "\n",
    "    df=pd.json_normalize(df)\n",
    "\n",
    "    is_list = df.apply(lambda x: any(isinstance(i, list) for i in x))\n",
    "\n",
    "    list_columns = is_list[is_list].index.tolist()\n",
    "    if(len(list_columns)>0):\n",
    "        list_df = df[list_columns].copy()\n",
    "\n",
    "        df = df.drop(list_columns, axis=1)\n",
    "        df['row_number'] = range(1, len(df) + 1)\n",
    "    main_table = pa.Table.from_pandas(df)\n",
    "    print(main_table)\n",
    "    if(len(list_columns)>0):\n",
    "        for dropped_list in list_columns:\n",
    "            new_json=make_new_json(list_df[dropped_list],dropped_list)\n",
    "            delete_lists(new_json,dropped_list)\n",
    "\n",
    "with open(path, encoding='utf-8') as f:\n",
    "    dt = json.load(f)\n",
    "\n",
    "delete_lists(dt,'main')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_json(y):\n",
    "    out = {}\n",
    "\n",
    "    def flatten(x, name=''):\n",
    "        if type(x) is dict:\n",
    "            for a in x:\n",
    "                attribute_name= name + a +'.'\n",
    "                flatten(x[a], attribute_name)\n",
    "        elif type(x) is list:\n",
    "            i = 0\n",
    "            for a in x:\n",
    "                attribute_name=name.rstrip('.') + '[' + str(i) + '].'\n",
    "                flatten(a, attribute_name)\n",
    "                i += 1\n",
    "        else:\n",
    "            out[name.rstrip('.')] = x\n",
    "\n",
    "    flatten(y)\n",
    "    return out\n",
    "\n",
    "results = []\n",
    "\n",
    "for path in paths_test:\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        dt = json.load(f)\n",
    "        \n",
    "    if isinstance(dt, list):\n",
    "        flattened_data = [flatten_json(item) for item in dt]\n",
    "    else:\n",
    "        flattened_data = [flatten_json(dt)]\n",
    "\n",
    "    df = pd.DataFrame(flattened_data)\n",
    "\n",
    "    table = pa.Table.from_pandas(df)\n",
    "    results.append(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pyarrow.Table\n",
      "title: string\n",
      "year: int64\n",
      "href: string\n",
      "extract: string\n",
      "thumbnail: string\n",
      "thumbnail_width: double\n",
      "thumbnail_height: double\n",
      "row_number: int64\n",
      "----\n",
      "title: [[\"After Dark in Central Park\",\"Clowns Spinning Hats\",\"Capture of Boer Battery by British\"]]\n",
      "year: [[1900,1900,1900]]\n",
      "href: [[null,\"Clowns_Spinning_Hats\",\"Capture_of_Boer_Battery_by_British\"]]\n",
      "extract: [[null,\"Clowns Spinning Hats is a black-and-white silent film featuring clowns throwing hats back and forth to each other. It was written and produced by Lubin Films and released April 7, 1900.\",\"Capture of Boer Battery by British is a black-and-white silent short docu-fiction film produced by James H. White for Edison Manufacturing Company in 1900. It is one minute in length and depicts the resistance of the Gordon Highlanders to the oncoming fire of the Boer's advance during the Boer War. It was filmed in West Orange, New Jersey USA and released April 14, 1900.\"]]\n",
      "thumbnail: [[null,null,\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Capture_of_Boer_Battery_by_British_1900_James_H_White_Thomas_Edison.webm/320px--Capture_of_Boer_Battery_by_British_1900_James_H_White_Thomas_Edison.webm.jpg\"]]\n",
      "thumbnail_width: [[null,null,320]]\n",
      "thumbnail_height: [[null,null,240]]\n",
      "row_number: [[1,2,3]], [pyarrow.Table\n",
      "__index_level_0__: null\n",
      "----\n",
      "__index_level_0__: [0 nulls]], [pyarrow.Table\n",
      "row_number: int64\n",
      "value: string\n",
      "----\n",
      "row_number: [[1,2,2,2]]\n",
      "value: [[\"Silent\",\"Short\",\"Documentary\",\"Silent\"]]]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pyarrow as pa\n",
    "from tqdm import tqdm\n",
    "\n",
    "def make_new_json(lists,table_name):\n",
    "    data = []\n",
    "    for i in range(len(lists)):\n",
    "        for item in lists[i]:\n",
    "            item_data={\n",
    "                \"row_number\": i,\n",
    "                \"value\": item\n",
    "            }\n",
    "            data.append(item_data)\n",
    "    return data\n",
    "\n",
    "def delete_lists(df,name):\n",
    "\n",
    "    df=pd.json_normalize(df)\n",
    "\n",
    "    is_list = df.apply(lambda x: any(isinstance(i, list) for i in x))\n",
    "\n",
    "    list_columns = is_list[is_list].index.tolist()\n",
    "    if(len(list_columns)>0):\n",
    "        list_df = df[list_columns].copy()\n",
    "        df = df.drop(list_columns, axis=1)\n",
    "        df['row_number'] = range(1, len(df) + 1)\n",
    "    main_table = pa.Table.from_pandas(df)\n",
    "    tables = [main_table]\n",
    "    if(len(list_columns)>0):\n",
    "        for dropped_list in list_columns:\n",
    "            new_json=make_new_json(list_df[dropped_list],dropped_list)\n",
    "            tables.append(delete_lists(new_json,dropped_list))\n",
    "    return tables\n",
    "path=paths_test[3]\n",
    "with open(path, encoding='utf-8') as f:\n",
    "    dt = json.load(f)\n",
    "\n",
    "tables = delete_lists(dt,'main')\n",
    "print(tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tusiu\\rectangularVShierarchical\\code-test\\new_table-test.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tusiu/rectangularVShierarchical/code-test/new_table-test.ipynb#X12sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(path, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tusiu/rectangularVShierarchical/code-test/new_table-test.ipynb#X12sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     dt \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tusiu/rectangularVShierarchical/code-test/new_table-test.ipynb#X12sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m tables \u001b[39m=\u001b[39m delete_lists(dt,\u001b[39m'\u001b[39;49m\u001b[39mmain\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tusiu/rectangularVShierarchical/code-test/new_table-test.ipynb#X12sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m results\u001b[39m.\u001b[39mappend(tables)\n",
      "\u001b[1;32mc:\\Users\\tusiu\\rectangularVShierarchical\\code-test\\new_table-test.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tusiu/rectangularVShierarchical/code-test/new_table-test.ipynb#X12sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     \u001b[39mfor\u001b[39;00m dropped_list \u001b[39min\u001b[39;00m list_columns:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tusiu/rectangularVShierarchical/code-test/new_table-test.ipynb#X12sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m         new_json\u001b[39m=\u001b[39mmake_new_json(list_df[dropped_list],dropped_list)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tusiu/rectangularVShierarchical/code-test/new_table-test.ipynb#X12sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m         tables\u001b[39m.\u001b[39mappend(delete_lists(new_json,dropped_list))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tusiu/rectangularVShierarchical/code-test/new_table-test.ipynb#X12sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39mreturn\u001b[39;00m tables\n",
      "\u001b[1;32mc:\\Users\\tusiu\\rectangularVShierarchical\\code-test\\new_table-test.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tusiu/rectangularVShierarchical/code-test/new_table-test.ipynb#X12sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mif\u001b[39;00m(\u001b[39mlen\u001b[39m(list_columns)\u001b[39m>\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tusiu/rectangularVShierarchical/code-test/new_table-test.ipynb#X12sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     \u001b[39mfor\u001b[39;00m dropped_list \u001b[39min\u001b[39;00m list_columns:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tusiu/rectangularVShierarchical/code-test/new_table-test.ipynb#X12sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m         new_json\u001b[39m=\u001b[39mmake_new_json(list_df[dropped_list],dropped_list)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tusiu/rectangularVShierarchical/code-test/new_table-test.ipynb#X12sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m         tables\u001b[39m.\u001b[39mappend(delete_lists(new_json,dropped_list))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tusiu/rectangularVShierarchical/code-test/new_table-test.ipynb#X12sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39mreturn\u001b[39;00m tables\n",
      "\u001b[1;32mc:\\Users\\tusiu\\rectangularVShierarchical\\code-test\\new_table-test.ipynb Cell 9\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tusiu/rectangularVShierarchical/code-test/new_table-test.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m data \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tusiu/rectangularVShierarchical/code-test/new_table-test.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(lists)):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/tusiu/rectangularVShierarchical/code-test/new_table-test.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m lists[i]:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tusiu/rectangularVShierarchical/code-test/new_table-test.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(item, \u001b[39mdict\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tusiu/rectangularVShierarchical/code-test/new_table-test.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m             \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m item\u001b[39m.\u001b[39mitems():\n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pyarrow as pa\n",
    "from tqdm import tqdm\n",
    "\n",
    "def make_new_json(lists,table_name):\n",
    "    data = []\n",
    "    for i in range(len(lists)):\n",
    "        for item in lists[i]:\n",
    "            if isinstance(item, dict):\n",
    "                for key, value in item.items():\n",
    "                    item_data={\n",
    "                        \"row_number\": i,\n",
    "                        key: value\n",
    "                    }\n",
    "                    data.append(item_data)\n",
    "            else:\n",
    "                item_data={\n",
    "                    \"row_number\": i,\n",
    "                    \"value\": item\n",
    "                }\n",
    "                data.append(item_data)\n",
    "    return data\n",
    "\n",
    "def delete_lists(df,name):\n",
    "\n",
    "    df=pd.json_normalize(df)\n",
    "\n",
    "    is_list = df.apply(lambda x: any(isinstance(i, list) for i in x))\n",
    "\n",
    "    list_columns = is_list[is_list].index.tolist()\n",
    "    if(len(list_columns)>0):\n",
    "        list_df = df[list_columns].copy()\n",
    "        df = df.drop(list_columns, axis=1)\n",
    "        df['row_number'] = range(1, len(df) + 1)\n",
    "    main_table = pa.Table.from_pandas(df)\n",
    "    tables = [main_table]\n",
    "    if(len(list_columns)>0):\n",
    "        for dropped_list in list_columns:\n",
    "            new_json=make_new_json(list_df[dropped_list],dropped_list)\n",
    "            tables.append(delete_lists(new_json,dropped_list))\n",
    "    return tables\n",
    "results=[]\n",
    "path=paths_test[4]\n",
    "with open(path, encoding='utf-8') as f:\n",
    "    dt = json.load(f)\n",
    "\n",
    "tables = delete_lists(dt,'main')\n",
    "results.append(tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[pyarrow.Table\n",
       " name: string\n",
       " id: string\n",
       " nametype: string\n",
       " recclass: string\n",
       " mass: string\n",
       " fall: string\n",
       " year: string\n",
       " reclat: string\n",
       " reclong: string\n",
       " geolocation.type: string\n",
       " row_number: int64\n",
       " ----\n",
       " name: [[\"Aachen\",\"Aarhus\",\"Abee\"]]\n",
       " id: [[\"1\",\"2\",\"6\"]]\n",
       " nametype: [[\"Valid\",\"Valid\",\"Valid\"]]\n",
       " recclass: [[\"L5\",\"H6\",\"EH4\"]]\n",
       " mass: [[\"21\",\"720\",\"107000\"]]\n",
       " fall: [[\"Fell\",\"Fell\",\"Fell\"]]\n",
       " year: [[\"1880-01-01T00:00:00.000\",\"1951-01-01T00:00:00.000\",\"1952-01-01T00:00:00.000\"]]\n",
       " reclat: [[\"50.775000\",\"56.183330\",\"54.216670\"]]\n",
       " reclong: [[\"6.083330\",\"10.233330\",\"-113.000000\"]]\n",
       " geolocation.type: [[\"Point\",\"Point\",\"Point\"]]\n",
       " ...,\n",
       " [pyarrow.Table\n",
       "  row_number: int64\n",
       "  value: double\n",
       "  ----\n",
       "  row_number: [[0,0,1,1,2,2]]\n",
       "  value: [[6.08333,50.775,10.23333,56.18333,-113,54.21667]]]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pyarrow as pa\n",
    "from tqdm import tqdm\n",
    "\n",
    "def make_new_json(lists,table_name):\n",
    "    data = []\n",
    "    for i in range(len(lists)):\n",
    "        if lists[i] is not None and not isinstance(lists[i], float):\n",
    "            for item in lists[i]:\n",
    "                if isinstance(item, dict):\n",
    "                    item_data = item.copy()\n",
    "                    item_data[\"row_number\"] = i\n",
    "                else:\n",
    "                    item_data={\n",
    "                        \"row_number\": i,\n",
    "                        \"value\": item\n",
    "                    }\n",
    "                data.append(item_data)\n",
    "    return data\n",
    "\n",
    "\n",
    "def delete_lists(df,name):\n",
    "\n",
    "    df=pd.json_normalize(df)\n",
    "\n",
    "    is_list = df.apply(lambda x: any(isinstance(i, list) for i in x))\n",
    "\n",
    "    list_columns = is_list[is_list].index.tolist()\n",
    "    if(len(list_columns)>0):\n",
    "        list_df = df[list_columns].copy()\n",
    "        df = df.drop(list_columns, axis=1)\n",
    "        df['row_number'] = range(1, len(df) + 1)\n",
    "    main_table = pa.Table.from_pandas(df)\n",
    "    tables = [main_table]\n",
    "    if(len(list_columns)>0):\n",
    "        for dropped_list in list_columns:\n",
    "            new_json=make_new_json(list_df[dropped_list],dropped_list)\n",
    "            tables += delete_lists(new_json,dropped_list)\n",
    "    return tables\n",
    "results=[]\n",
    "for path in paths:\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        dt = json.load(f)\n",
    "\n",
    "    tables = delete_lists(dt,'main')\n",
    "    results.append(tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pyarrow as pa\n",
    "from tqdm import tqdm\n",
    "\n",
    "def make_new_json(lists,table_name):\n",
    "    data = []\n",
    "    for i in range(len(lists)):\n",
    "        if lists[i] is not None and not isinstance(lists[i], float):\n",
    "            for item in lists[i]:\n",
    "                if isinstance(item, dict):\n",
    "                    item_data = item.copy()\n",
    "                    item_data[\"row_number\"] = i\n",
    "                else:\n",
    "                    item_data={\n",
    "                        \"row_number\": i,\n",
    "                        \"value\": item\n",
    "                    }\n",
    "                data.append(item_data)\n",
    "    return data\n",
    "\n",
    "\n",
    "def delete_lists(df,name):\n",
    "\n",
    "    df=pd.json_normalize(df)\n",
    "\n",
    "    is_list = df.apply(lambda x: any(isinstance(i, list) for i in x))\n",
    "\n",
    "    list_columns = is_list[is_list].index.tolist()\n",
    "    if(len(list_columns)>0):\n",
    "        list_df = df[list_columns].copy()\n",
    "        df = df.drop(list_columns, axis=1)\n",
    "        df['row_number'] = range(1, len(df) + 1)\n",
    "    main_table = pa.Table.from_pandas(df)\n",
    "    tables = [main_table]\n",
    "    if(len(list_columns)>0):\n",
    "        for dropped_list in list_columns:\n",
    "            if all(isinstance(item, dict) for item in list_df[dropped_list]):\n",
    "                flattened_data = [flatten_json(item) for item in list_df[dropped_list]]\n",
    "            else:\n",
    "                flattened_data = list_df[dropped_list]\n",
    "            new_json=make_new_json(flattened_data,dropped_list)\n",
    "            tables += delete_lists(new_json,dropped_list)\n",
    "    return tables\n",
    "\n",
    "results=[]\n",
    "for path in paths:\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        dt = json.load(f)\n",
    "\n",
    "    tables = delete_lists(dt,'main')\n",
    "    results.append(tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[pyarrow.Table\n",
       " title: string\n",
       " year: int64\n",
       " href: string\n",
       " extract: string\n",
       " thumbnail: string\n",
       " thumbnail_width: double\n",
       " thumbnail_height: double\n",
       " row_number: int64\n",
       " ----\n",
       " title: [[\"After Dark in Central Park\",\"Boarding School Girls' Pajama Parade\",\"Buffalo Bill's Wild West Parad\",\"Caught\",\"Clowns Spinning Hats\",...,\"Aquaman and the Lost Kingdom\",\"Untitled Ghostbusters: Afterlife sequel\",\"Rebel Moon\",\"Migration\",\"The Color Purple\"]]\n",
       " year: [[1900,1900,1900,1900,1900,...,2023,2023,2023,2023,2023]]\n",
       " href: [[null,null,null,null,\"Clowns_Spinning_Hats\",...,\"Aquaman_and_the_Lost_Kingdom\",\"Untitled_Ghostbusters:_Afterlife_sequel\",\"Rebel_Moon\",\"Migration_(2023_film)\",\"The_Color_Purple_(2023_film)\"]]\n",
       " extract: [[null,null,null,null,\"Clowns Spinning Hats is a black-and-white silent film featuring clowns throwing hats back and forth to each other. It was written and produced by Lubin Films and released April 7, 1900.\",...,\"Aquaman and the Lost Kingdom is an upcoming American superhero film based on the DC Comics character Aquaman. Produced by DC Studios, the Safran Company, and Atomic Monster Productions, and set for distribution by Warner Bros. Pictures, it is intended to be the sequel to Aquaman (2018), and the 15th and final installment in the DC Extended Universe (DCEU). The film is directed by James Wan from a screenplay written by David Leslie Johnson-McGoldrick, and stars Jason Momoa as Arthur Curry / Aquaman alongside Amber Heard, Willem Dafoe, Patrick Wilson, Dolph Lundgren, Yahya Abdul-Mateen II, Temuera Morrison, and Nicole Kidman.\",\"The untitled Ghostbusters: Afterlife sequel is an upcoming American supernatural comedy film directed by Gil Kenan from a screenplay co-written by Jason Reitman and Kenan. It serves as the sequel to Ghostbusters: Afterlife (2021), and the fifth film in the Ghostbusters franchise. The film stars Finn Wolfhard, Mckenna Grace, Celeste O'Connor, Carrie Coon, Paul Rudd and Ernie Hudson reprising their roles, with new additions to the cast including Kumail Nanjiani, Patton Oswalt, James Acaster and Emily Alyn Lind.\",\"Rebel Moon is an upcoming American epic space opera film directed by Zack Snyder from a screenplay he co-wrote with Shay Hatten and Kurt Johnstad, based on a story he also created with Johnstad. Produced by The Stone Quarry and Grand Electric, and distributed by Netflix. The film features an ensemble cast that includes Sofia Boutella, Charlie Hunnam, Ray Fisher, Djimon Hounsou, Jena Malone, Corey Stoll, Ed Skrein, Cleopatra Coleman, Fra Fee, Cary Elwes, and Anthony Hopkins.\",\"This is a list of productions produced by Illumination, an American film and animation studio based in Santa Monica, California, United States. This includes feature films, television specials, shorts, and digital series. As of 2023, Illumination has released 13 feature films, which were all distributed by Universal Pictures, with their first being Despicable Me on July 9, 2010, and their latest being The Super Mario Bros. Movie on April 5, 2023.\",\"The Color Purple is an upcoming American musical coming-of-age period drama film directed by Blitz Bazawule and adapted for the screen by Marcus Gardley from the 2005 stage musical of the same name, which is in turn based on Alice Walker's 1982 Pulitzer Prize-winning novel of the same name. It is the second film adaptation of the novel, following Steven Spielberg's 1985 film adaptation. Spielberg and Quincy Jones return to produce this version, along with the stage musical's producers Scott Sanders and Oprah Winfrey, the latter of whom also starred in the 1985 film as Sofia.\"]]\n",
       " thumbnail: [[null,null,null,null,null,...,\"https://upload.wikimedia.org/wikipedia/en/thumb/f/f9/Aquaman_and_the_Lost_Kingdom_logo.jpg/320px-Aquaman_and_the_Lost_Kingdom_logo.jpg\",null,null,null,null]]\n",
       " thumbnail_width: [[null,null,null,null,null,...,320,null,null,null,null]]\n",
       " thumbnail_height: [[null,null,null,null,null,...,163,null,null,null,null]]\n",
       " row_number: [[1,2,3,4,5,...,36269,36270,36271,36272,36273]],\n",
       " pyarrow.Table\n",
       " row_number: int64\n",
       " value: string\n",
       " ----\n",
       " row_number: [[7,16,107,144,244,...,36272,36272,36272,36272,36272]]\n",
       " value: [[\"Paul Boyton\",\"Ching Ling Foo\",\"May Clark\",\"William Carrington\",\"J. Stuart Blackton\",...,\"Elizabeth Marvel\",\"Jon Batiste\",\"Louis Gossett Jr.\",\"David Alan Grier\",\"Taraji P. Henson\"]],\n",
       " pyarrow.Table\n",
       " row_number: int64\n",
       " value: string\n",
       " ----\n",
       " row_number: [[4,5,5,5,6,...,36269,36270,36272,36272,36272]]\n",
       " value: [[\"Silent\",\"Short\",\"Documentary\",\"Silent\",\"Silent\",...,\"Supernatural\",\"Science Fiction\",\"Drama\",\"Musical\",\"Historical\"]]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
